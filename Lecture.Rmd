---
subtitle: "Lecture for class: Data science in the Humanities"
title: "Big data in the acoustic phonetic analysis"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
 
author: "Peter Gilles"
date: "29. April 2020, 14h00 - 16h00, University of Luxembourg"
output:
  #tufte::tufte_html:
  #tufte::tufte_handout: 
  html_notebook: 
    toc: true
    toc_depth: 2
    number_sections: true
---

This tutorial will demonstrate how to analyse audio data for acoustic phonetic studies in R. It is mainly intended to demonstrated possible workflows. The topics covered are:

* phonetic databases, the case of `emuR` and `EMU-SDMS`, the EMU Speech Database Management System
* Sample data: the LOD database
* Queries and requeries
* Inscpect the database: `serve()`
* Calculate duration for vowel categories
* Vowels formants and visualisations with `ggplot2`
* Vowel explorer
* Calculating the Pillai distance

# Preamble {-}

The generated HTML page of this tutorial is available [here](https://petergilles.github.io/Data_Science_Humanities/index.nb.html).

This tutorial is organised as  an [R Markdown](http://rmarkdown.rstudio.com) notebook. To execute the code within this notebook (filename `Lecture.Rmd`) it has to be opend in RStudio. When executing code, the results appear beneath the code. In order to do so, you need to have R and RStudio installed. When this R notebook is loaded into RStudio, you can excecute chunks by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*, allowing you to experiment with the code. This handout contains all output of the code (tables, visualisations etc.). The easiest way to work with this R code is to clone the entire project from this GitHub repository.

The following libraries will be needed and have to be installed.
```{r Libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggiraph)
library(cowplot)
library(emuR)
library(tools)
library(rio)
library(ggplot2)
library(magrittr)
library(ggiraph)
library(htmltools)
library(shiny)
library(joeyr)
library(knitr)
```


# The LOD database

The database contains the audio recordings from the `Lëtzebuerger Online Dictionnaire` (available [here](https://github.com/spellchecker-lu), spoken by one female speaker. The audio files have been automatically segmented with the [MAUS tools](https://clarin.phonetik.uni-muenchen.de/BASWebServices/interface). We thus have a database conisting of textual data, basically words, and the corresponding audio data. The audio data is segmented into words and phonetic segments (sounds).

This database has been created beforehand. Infos how to create such a database is explained in the [EMU-SDMS manual](https://ips-lmu.github.io/The-EMU-SDMS-Manual/).

While we will be working with the full database (26.000 recordings), a small demo database `lod_emuDB` has been created with 500 recordings which can be used for individual testing.

We start with loading the database and give an overview of structure and content.
```{r}
# load database
db = load_emuDB("/Users/peter.gilles/Documents/_Daten/LOD-emuDB/lod_emuDB")
#db = load_emuDB("lod_emuDB")

# display the overview of the structure and content
summary(db)

```

Tracks in `emuR` are acoustic representation of the speech signal, here `dft` for the waveform (time-amplitude representation) and `praatFms` for the formant measures of vowels (see below). 

Levels in an `eumR` database stand for level of interlinked linguistic information. `bundle` is the entire audio file, `ORT` stands for the orthographical representation of the audio file segmented in its single words. `MAU` is the segmentation of all phonetic segment (=sounds) of all `ORT` segments in `bundle`.

The hierarchical structure of these levels is expressed in the `link definitions` as `ONE-TO-MANY`.

# Database queries

An emuR database can be queried with a powerful query engine. The first example is a simple query for one word, `Aarbecht`.

```{r}
sl = query(db, query = "[ ORT == 'Aarbecht']")
sl
```

The result is a `segment list` (`sl`), containing various information about the found item (time, level, name, database info). The result of the query can also be displayed in the EMU Speech Database Management System. 

`serve(db, seglist = sl)`

The GUI will open in the `Viewer` pane of RStudio or you can open it in a browser (Chrome preferred).

```{r echo=FALSE}
knitr::include_graphics(rep("emu-sdms.png"))
```

Here we can also display the hiearchical structure for this database item, which is accessed during queries. `bundle` is the top-level, representing the entire audio file. 

The `ORT` level contains the nodes for the individual words in the `bundle`, here the two words `Aarbecht` and `Aarbechten`. The dependend level then is `MAU` (=`Munich Automatic Unit`) representing the single sounds of the words in `ORT`. 

```{r echo=FALSE}
knitr::include_graphics(rep("hierarchy.png"))
```

Two aspects render emuR query system extremly powerful: the use of regular expressions (including negation and other extensions) and the combinated query on different levels of the database.

Let's try more complex queries:

- regular expression, operator `=~`, words beginning with `Aarbecht...`
```{r}
sl = query(db, query = "[ ORT =~ 'Aarbecht.*']")
sl
```

Select the vowel [aː] in all words beginning with `Aarbecht`... Note that in the segment list the label now has changed to the vowel and the respective start-end information is now only for this sound [aː].

```{r}
sl = query(db, query = "[ ORT =~ 'Aarbecht.*' ^ #MAU=='aː']")
sl

```

- query a sequence of sounds, e.g. `e` followed by `k` (`Méck`), by using the sequence operator `->`.

```{r}
sl = query(db, query = "[ MAU == e -> MAU == k ]")
# print only the first 100 rows
sl[1:100, ]

```

- in the sequence `e->k`, query only the vowel. Use the result modifier `#`.

```{r}
sl = query(db, query = "[ #MAU == e -> MAU == k ]")
# print only the first 100 rows
sl[1:100, ]
```

```{r}
# query all sound items that occur
# at the end of a word and are `p`
sl <- query(db, query = "[End(ORT, MAU) == TRUE & MAU == p ]")
sl
```

```{r}
# retrieve all word that contain five segments
sl <- query(db, "[Num(ORT, MAU) == 5]")
sl
```

* using `requery` the results from a previous query can be further specified

```{r}
# requery_seq()

# query all "m" phonetic items
sl_m = query(db, "MAU == m")

# sequential requery (left shift result by 1 (== offset of -1))
# and hence retrieve all phonetic items directly preceeding
# all "m" phonetic items
sl_req_n <- requery_seq(db, 
            seglist = sl_m, 
            offset = -1)
sl_req_n
```

* groups auf sounds can be grouped together to `label groups`, e.g. all long monophthongs (`"iː", "uː", "aː", "oː", "ɔː", "ɛː", "eː"`) or all short monophthongs (`"i", "u", "ɑ", "o", "æ", "e", "ə", "ɐ"`).

```{r}
# query all "m" phonetic items
sl = query(db, "MAU == longMonophthongs")
sl
```

With the query the user can compile the data frame from the database which then forms the subset for the phonetic analysis. We can select e.g. all instances of certain (or all) vowels, specifying the context before or after etc. etc.

Of course, querying for individual segments in the audio file like words or sounds is possible only, if this information has been added to the database before.


# Signal processing in R

The first task is to extract the time-amplitude waveform representation (oscillogram) for certain single sounds, e.g. some long `aː`.

```{r}
# query all "aː" phonetic items
# 
sl = query(db, "MAU == aː")
# instead of all 7,000 vowels take only 6
sl = sl[100:105, ]

```

The data for the oscillogram is stored in the SSF track `dft`, which is extracted by `get_trackdata`. The result is another R dataframe.

```{r}
# get "dft" track data for these segments
a_vowels = get_trackdata(emuDBhandle = db,
                         seglist = sl,
                         ssffTrackName = "MEDIAFILE_SAMPLES",
                         verbose = TRUE)
```

The oscillograms for these 6 vowel instances can then be visualised with `ggplot2`.

```{r}
# plot oscillogram
ggplot(data = a_vowels) + 
  # define the df columns for the x and y values
  aes(y = T1, x = times_rel) + 
  # line chart
  geom_line() + 
  # sl_rowIdx groups all rows in a dataframe belonging to the same segment
  # labels contains the label of the segment
  facet_wrap(~ sl_rowIdx + labels)
```

```{r}
# query all words beginning with 'Fluch'
# 
sl = query(db, query = "[ ORT =~ 'Fluch.*']")

# get "f0" track data for these segments, in this case calculated on the fly
fluch_words = get_trackdata(emuDBhandle = db,
                         seglist = sl,
                         # using emuR's Michel Scheffers’ Modified Harmonic
                         # Sieve algorithm 
                         onTheFlyFunctionName = "mhsF0",
                         verbose = TRUE)
```

In the corresponding graphs then the track for the fundamental frequency (f0) for some isolated words will be drawn.

```{r}
# plot f0 tracks
ggplot(data = fluch_words) + 
  # define the df columns for the x and y values
  # T1 here is the f0 value
  aes(y = T1, x = times_rel) + 
  # line chart
  geom_line() + 
  # sl_rowIdx groups all rows in a dataframe belonging to the same segment
  # labels contains the label of the segment
  facet_wrap(~ sl_rowIdx + labels)
```

If needed, you can check the content of your segment list with the EMU WebApp running `serve(seglist = sl)`.

# Calculate duration for vowel categories

The study of duration of speech segments is a standard task in acoustic phonetics. Let's see how to solve this in `R`. Thanks to the `label groups` which are available in the database, we have easy access to e.g. all `shortMonophthongs` and all `longMonophthongs`.

```{r}
# query all "m" phonetic items
longMonophthongs = query(db, "MAU == longMonophthongs")
shortMonophthongs = query(db, "MAU == shortMonophthongs")

# print the count; number of rows
nrow(longMonophthongs)
nrow(shortMonophthongs)
```

The data frame contains per segment a start and end column, which allows for simple calculation of the segment duration.

```{r}
# calculate durations
duration_long = longMonophthongs$end - longMonophthongs$start
duration_short = shortMonophthongs$end - shortMonophthongs$start

# calculate mean and standard deviation
paste("The mean duration for long monophthongs in the databse is", round(mean(duration_long)), "ms. The standard deviation is:", sd(duration_long), ".")

paste("The mean duration for short monophthongs in the databse is", round(mean(duration_short)), "ms. The standard deviation is:", sd(duration_short), ".")
```

From here on the duration values can be utilised in further statistical analyses.

# Vowels formants and visualisations with `ggplot2`
todo

# Calculate the Pillai distance

## from https://joeystanley.com/blog/a-tutorial-in-calculating-vowel-overlap

```{r echo=FALSE}
knitr::include_graphics(rep("https://joeystanley.com/images/plots/overlap_tutorial/pillai_example.png"))
```

# Vowel explorer

Try it [here](https://petergill.shinyapps.io/shinyplay/).

```{r}

knitr::include_app("https://petergill.shinyapps.io/shinyplay/")

```



